## Лаба 2. Загрузить данные в HBase из большого лог-файла, лежащего в HDFS с помощью MapReduce

### Дедлайн

⏰ Вторник, 9 апреля 2019 года, 23:59 по Москве.


### Задача
Вы разрабатываете новую рекламную кампанию и хотите среди всех пользователей выбрать только тех, кто соответствует определенной категории интересов. UID пользователя в данных генерировался не случайно, а в него закладывалась информация о категории интереса пользователя.

Для решения задачи вам нужно загрузить данные из кластерного HDFS в HBase при помощи MapReduce, осуществив предварительную фильтрацию данных.

##### Напомним несколько полезных вещей:

Можно просмотреть содержимое директорий:
`hadoop fs -ls /`

Просмотреть содержимое файлов (первые 100 строк файла `part-00000`):

`hadoop fs -cat /labs/lab02data/facetz_2015_02_01/part-00000 | head -n100`

Скачать файл с HDFS на локальную машину:

`hadoop fs -get /labs/lab02data/facetz_2015_02_01/part-00000`


#### Веб-интерфейс кластера

Для вас поднят Hadoop-кластер (включая HDFS/HBase/YARN), ресурсы которого вы можете посмотреть через Ambari.

Веб-интерфейс Ambari доступен по адресу: http://master.cluster-lab.com:8080/

Доступ к кластерному Ambari — по логину/паролю от ЛК.

В состав кластера входят 6 узлов, один из которых предназначен для запуска MapReduce-задач, а остальные являются рабочими нодами для выполнения вычислений (хотя это не единственная их функция). Рекомендуем сразу зайти в список хостов и посмотреть, какие сервисы находятся на каждом из них: http://master.cluster-lab.com:8080/#/main/hosts — например, можете сами определить, к какому хосту нужно подключаться для доступа к Thrift-интерфейсу HBase (к master).

#### Подключение к гейтвею кластера по SSH
У вас теперь один общий кластер с хостнеймом `master.cluster-lab.com`. Доступ к кластеру осуществляется по адресу и ключу, которые можно взять на странице Личного кабинета (тот же, что в предыдущей лабе), а в качестве логина использовать логин к Личному кабинету.

Пример:

`ssh -i npl.pem john.smith@master.cluster-lab.com`

Мы снова, как и в Лабе #1, рекомендуем вам прописать профиль подключения к кластеру в `~/.ssh/config`, чтобы подключаться к гейтвею кластера без лишних сложностей. Гейтвей `master.cluster-lab.com` будет вашей дефолтной машиной для работы через ssh до конца курса.

#### Структура данных facetz на HDFS

Ваш пользователь на кластере уже имеет все необходимые права и доступы к бинарникам, позволяющим работать с HDFS, поэтому логиниться под `hdfs` не нужно, и неполучится, так как у вас нет админскистраторских привилегий на этом кластере.

Исходные файлы расположены **в HDFS** общего кластера в директориях по адресу 
`/labs/lab02data/facetz_YYYY_MM_DD/`, где YYYY_MM_DD - дата. 
В директориях расположены файлы вида `part-NNNNN`, где `NNNNN` - порядковый номер файла.

Каждый файл представляет собой коллекцию записей, по записи на строчку, где каждая строка представляет собой кортеж `(UID, timestamp, URL)`.
* `UID` — уникальный идентификатор пользователя, представленный натуральным числом, записанным в десятичной форме. 
* `timestamp` — отметка времени, записанная в форме UNIX timestamp, записана в виде десятичной дроби. 
* `URL` — экранированный URL, представлен в виде строки. 
* Записи разделены символом табуляции `\t`.

Пример:

`26153949061	1422751272.768	http%3A%2F%2Frzd.ru%2F`

#### Обработка данных на вход
Для выполнения работы вам следует **взять все файлы** из директории, которая указана в [Личном кабинете](http://lk.newprolab.com/lab/lab02).

⚠️ Замечание: неправильно сформированные строки следует игнорировать.
Неправильные строки — строки, в которых нет хотя бы одного из трёх элементов, в `URL` или в `UID` указан прочерк, или, вообще, неверный формат. URL должны начинаться с http.

Вам необходимо оставить только те строки, для которых выполняется индивидуальное условие: `UID mod 256 == N`, где N берётся из [Личного кабинета](http://lk.newprolab.com/lab/lab02).

URL не нужно нормализовывать, вообще никак преобразовывать.

#### Обработка данных на выход
⚠️ Важно: Название таблицы, которую вам необходимо заполнить, должно совпадать с логином ЛК.

⚠️ Важно: Если вы собираетесь что-то заливать в HDFS, пожалуйста, делайте это в своей HDFS-директории: `/user/[ваше-имя-пользователя]`

В нашем примере таблица должна называться `john.smith`, для каждой записи должно храниться 4096 версий.

Содержимое таблицы должно представлять собой rowkey=`uid` и column=`data:url`. Отметка времени в базе должна совпадать с отметкой в файле, а не с моментом, когда запись попала в базу. 

❗️**Обратите внимание:** отметку надо умножить на 1000 и привести к int: `int(ts * 1000)`.

#### Подсказки и советы
**[1]** Для загрузки данных из python предлагаем воспользоваться библиотекой Happybase (https://happybase.readthedocs.io/en/latest/user.html).

Эта библиотека уже установлена на кластере в питоновской conda-среде bd9. Чтобы работать в этой среде интерактивно на мастере, исполните команду:

`conda activate bd9` 

Подключаться с помощью `happybase` нужно к хосту `master.cluster-lab.com`. Пример создания соединения в программе на python:

```
#!/opt/anaconda/envs/bd9/bin/python
import happybase
connection = happybase.Connection('master.cluster-lab.com')
```

Вы так же можете воспользоваться консольной утилитой hbase, которая запускается для интерактивной работы вот так:

`hbase shell`

но может быть использована и для пакетного запуска команд.

Смотрите парочку страниц с документацией и примерами:

https://learnhbase.wordpress.com/2013/03/02/hbase-shell-commands/

http://hbase.apache.org/book.html#shell


**[2]** Сначала напишите программу которая принимает на stdin файл и складывает его в вашу базу в HBase. Если локально отработает — запускайте на hadoop.

**[3]** Чтобы не прописывать постоянно длинный путь к jar-файлу для запуска hadoop-streaming, скопируйте его себе в домашнюю директорию:

`cp /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar ~/hadoop-streaming.jar`

или сделайте символическую ссылку:

`ln -s /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar ~/hadoop-streaming.jar`


**[4]** В первой строчке исполняемого python-файла нужно прописать путь к интерпретатору `#!/opt/anaconda/envs/bd9/bin/python` - это гарантия того, что ваша программа найдет модуль happybase на всех узлах кластера. Не забудьте сделать ваши питоновские файлы исполняемыми.

**[5]** Если у вас MapReduce job выдаёт ошибки, то для дебага воспользуйтесь http-ссылкой на статус джобы. Её можно найти в логе инициализации джобы, который выводится вам в консоль:

```
18/10/03 11:16:33 INFO impl.YarnClientImpl: Submitted application application_1535642361485_0060
18/10/03 11:16:34 INFO mapreduce.Job: The url to track the job: http://master.cluster-lab.com:8088/proxy/application_1535642361485_0060/
```

В веб-интерфейсе нажмите на ссылку "logs", по которой вы получите достаточно логов (в том числе, stderr-вывод python-скрипта, в котором у вас наверняка и есть ошибка):

```
Log Type: stderr
Log Upload Time: Fri Mar 10 15:15:45 +0300 2017
Log Length: 498
Traceback (most recent call last):
  File "/disk1/hadoop/yarn/local/usercache/hdfs/appcache/application_1488372559028_0002/container_e01_1488372559028_0002_01_000034/./m.py", line 4, in <module>
    import happybase
ImportError: No module named happybase
```

:warning: Важно! Доступ к логам возможен только через [прокси](../../extra/proxy.md)!

**[6]** У HBase есть веб-интерфейс: http://master.cluster-lab.com:16010/master-status. Здесь вы, например, можете посмотреть, какие таблицы созданы и есть ли среди них ваша.

#### Проверка
Проверка осуществляется автоматическим скриптом из личного кабинета. В личном кабинете существует раздел “Результаты”. Там можно будет увидеть результаты всех пройденных лаб.


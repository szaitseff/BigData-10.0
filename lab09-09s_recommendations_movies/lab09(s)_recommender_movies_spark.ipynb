{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лаба 9. Ваш собственный алгоритм рекомендаций фильмов\n",
    "\n",
    "### Дедлайн\n",
    "\n",
    "⏰ Четверг, 13 июня 2019 года, 23:59.\n",
    "\n",
    "### Задача\n",
    "\n",
    "Нужно построить рекомендательный алгоритм наилучшей предсказательной точности по метрике RMSE.\n",
    "\n",
    "### Обработка данных на вход\n",
    "\n",
    "Имеются следующие входные данные:\n",
    "\n",
    "* Имеется табличка рейтингов `train.csv`. Формат: `userId, movieId, rating`. Вам отдаётся случайная половина этой таблички (рандомизация по items и users), половина остается нам. Мы используем скрытый датасет для оценки качества предсказания по RMSE. \n",
    "* Табличка `tags.csv` с текстовыми тэгами, которые пользователя проставил фильму. Формат: `userId, movieId, tag`.\n",
    "* Табличка `movies.csv` с названием фильма и его жанром. Формат: `movieId, title, genres`.\n",
    "* Табличка `links.csv` соответствия id фильма с базами данных imdb и themoviedb, в которых можно найти дополнительные характеристики фильмов. Формат: `movieId, imdbId, tmdbId`. \n",
    "* Табличка `test.csv`, для которой надо сгенерировать предсказания.\n",
    "\n",
    "Для выполнения работы вам следует взять все файлы из папки на HDFS `/labs/lab09data/`.\n",
    "\n",
    "### Подсказки\n",
    "\n",
    "* Вы можете использовать любые алгоритмы и их смеси (NP, User-user, Item-item, SVD, ALS...) для предсказания рейтингов. \n",
    "* Вы также можете использовать дополнительные content данные для обогащения вашего алгоритма (`tags.csv, movies.csv, links.csv`)\n",
    "* Обучив свой алгоритм на таблице с рейтингами `train.csv`, нужно сгенерировать предсказания для таблички `test.csv` и засабмитить.\n",
    "* В `test.csv` могут попасть пользователи, по которым у вас в `train.csv` нет (или мало) наблюдений. Придумайте, что с ними делать (дефолтные рейтинги?).\n",
    "\n",
    "### Проверка\n",
    "\n",
    "Мы будем оценивать точность работы вашего алгоритма по метрике среднего квадратичного отклонения предсказанного рейтинга от истинного рейтинга RMSE: \n",
    "\n",
    "<img width=\"350px\" src=\"laba09_rmse.png\">\n",
    "\n",
    "**Важно!** Для точной проверки сохраняйте порядок и количество строк исходного файла `test.csv` (сортировка там идет по целочисленному `userId`, а потом по `movieId`). Названия колонок и сепаратор так же следует сохранить. Файл `test.csv` сам является образцом для засылки.\n",
    "\n",
    "**Если RMSE вашей рекомендательной системы будет ниже 0.9, то лаба будет засчитана.**\n",
    "\n",
    "Результат следует сохранить в файл `lab09.csv` в своей домашней директории.\n",
    "\n",
    "Проверка осуществляется [автоматическим скриптом](http://lk.newprolab.com/lab/laba09) из Личного кабинета.\n",
    "\n",
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.3\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# Запуск pyspark\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sc.setCheckpointDir('checkpoint/')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Прокидываем порты\n",
    "!ssh bdmaster -L 8088:localhost:8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\r\n",
      "-rw-r--r--   3 hdfs hdfs     561456 2018-09-13 13:49 /labs/lab09data/links.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs    1390073 2018-09-13 13:49 /labs/lab09data/movies.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   11364859 2018-09-13 13:49 /labs/lab09data/tags.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  169754328 2018-09-13 13:49 /labs/lab09data/test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  169755196 2018-09-13 13:49 /labs/lab09data/train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /labs/lab09data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!hadoop fs -head /labs/lab09data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|   2244|   4.5|\n",
      "|     1|   2464|   4.5|\n",
      "|     1|   6361|   4.5|\n",
      "|     1|  10620|   4.5|\n",
      "|     1|  12012|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.csv('/labs/lab09data/train.csv', inferSchema=True, header=True)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            userId|           movieId|            rating|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|          10531564|          10531564|          10531564|\n",
      "|   mean|114525.73807926344|13712.597933602265|3.5218638466233507|\n",
      "| stddev| 66094.26611665961| 7860.215369765642| 1.058361838990463|\n",
      "|    min|                 1|                 1|               0.5|\n",
      "|    25%|             57387|              6812|               3.0|\n",
      "|    50%|            114363|             13705|               3.5|\n",
      "|    75%|            171482|             20611|               4.0|\n",
      "|    max|            229060|             27302|               5.0|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%time train.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# count unique users\n",
    "%time train.agg(countDistinct('userId')).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# count unique movies\n",
    "%time train.agg(countDistinct('movieId')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!hadoop fs -head /labs/lab09data/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|   1414|   0.0|\n",
      "|     1|   2346|   0.0|\n",
      "|     1|   5278|   0.0|\n",
      "|     1|   9303|   0.0|\n",
      "|     1|  11817|   0.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.read.csv('/labs/lab09data/test.csv', inferSchema=True, header=True)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------+\n",
      "|summary|            userId|           movieId|  rating|\n",
      "+-------+------------------+------------------+--------+\n",
      "|  count|          10531564|          10531564|10531564|\n",
      "|   mean|114525.72723301116|13711.874988273346|     0.0|\n",
      "| stddev| 66094.26609743753|  7860.38945378376|     0.0|\n",
      "|    min|                 1|                 1|     0.0|\n",
      "|    25%|             57387|              6812|     0.0|\n",
      "|    50%|            114373|             13705|     0.0|\n",
      "|    75%|            171494|             20611|     0.0|\n",
      "|    max|            229060|             27303|     0.0|\n",
      "+-------+------------------+------------------+--------+\n",
      "\n",
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%time test.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# count unique users\n",
    "%time test.agg(countDistinct('userId')).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# count unique movies\n",
    "%time test.agg(countDistinct('movieId')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS in Spark MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rmse evaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse', predictionCol='prediction', labelCol='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Journal\n",
    "\n",
    "maxIter | regParam | rank | nonnegative | rmse_train | rmse_test | clamp/na.fill | time\n",
    ":--- | :---: | :---: | :---: | :---: | :--- | :--- |\n",
    "10 | 0.1 | 8 | True | 0.7673 | 0.8321 | -/3.5 |\n",
    "20 | 0.01 | 10 | True | 0.6922  | 0.8581 | 0.5/3.5  |1m57s\n",
    "50 | 0.01 | 20 | True | 0.6177 | 0.8758 | 3.5/3.5  | 7m37s\n",
    "30 | 0.1 | 8 | True | 0.7547 | 0.8276  | 0.5/5.0/3.52  | 2m9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 12 ms, total: 28 ms\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=30, regParam=0.1, rank=8, nonnegative=True, coldStartStrategy=\"nan\",\\\n",
    "          userCol='userId', itemCol='movieId', ratingCol='rating')\n",
    "\n",
    "% time model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "| 75052|    148|   3.0| 2.9280884|\n",
      "|109268|    148|   3.0| 2.8745887|\n",
      "| 19362|    463|   3.0| 3.2669127|\n",
      "|  6990|    463|   4.5| 3.8141394|\n",
      "|189548|    463|   4.0| 3.4103394|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "#Let see how the model perform on train set\n",
    "predict_train = model.transform(train)\n",
    "%time predict_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = predict_train.coalesce(4).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 18.7 s\n",
      "Root mean squared error of the train_data: 0.7547829501877498\n"
     ]
    }
   ],
   "source": [
    "# check the root mean squared error on train set\n",
    "%time rmse_train = evaluator.evaluate(predict_train)\n",
    "print(f'Root mean squared error of the train_data: {rmse_train}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "avgRating = train.select('rating').groupBy().avg()\n",
    "avgRating.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|155572|    148|   0.0| 2.9904509|\n",
      "| 94231|    148|   0.0| 3.3644466|\n",
      "|178586|    148|   0.0| 2.6055057|\n",
      "|  3855|    148|   0.0| 2.4866748|\n",
      "|198955|    463|   0.0| 3.7445066|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "predict_test = model.transform(test)\n",
    "%time predict_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = predict_test.coalesce(4).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------+----------+\n",
      "|summary|            userId|           movieId|  rating|prediction|\n",
      "+-------+------------------+------------------+--------+----------+\n",
      "|  count|          10531564|          10531564|10531564|  10531564|\n",
      "|   mean|114525.72723301116|13711.874988273346|     0.0|       NaN|\n",
      "| stddev| 66094.26609743979|7860.3894537839815|     0.0|       NaN|\n",
      "|    min|                 1|                 1|     0.0|       0.0|\n",
      "|    25%|             57415|              6812|     0.0| 2.9837773|\n",
      "|    50%|            114390|             13705|     0.0|  3.546124|\n",
      "|    75%|            171498|             20611|     0.0| 4.0359564|\n",
      "|    max|            229060|             27303|     0.0|       NaN|\n",
      "+-------+------------------+------------------+--------+----------+\n",
      "\n",
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "%time predict_test.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in NaN and zero values in predict_test with avgRating (approx 3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------+------------------+\n",
      "|summary|            userId|           movieId|  rating|        prediction|\n",
      "+-------+------------------+------------------+--------+------------------+\n",
      "|  count|          10531564|          10531564|10531564|          10531564|\n",
      "|   mean|114525.72723301116|13711.874988273346|     0.0| 3.415006611794796|\n",
      "| stddev| 66094.26609743858| 7860.389453783982|     0.0|0.6512843965369679|\n",
      "|    min|                 1|                 1|     0.0|               0.5|\n",
      "|    25%|             57406|              6812|     0.0|3.0246684551239014|\n",
      "|    50%|            114412|             13705|     0.0| 3.477482795715332|\n",
      "|    75%|            171523|             20611|     0.0| 3.869719982147217|\n",
      "|    max|            229060|             27303|     0.0|               5.0|\n",
      "+-------+------------------+------------------+--------+------------------+\n",
      "\n",
      "CPU times: user 4 ms, sys: 4 ms, total: 8 ms\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "predict_clean = predict_test \\\n",
    "            .withColumn(\"prediction\", when(col(\"prediction\") < 0.5, 0.5).otherwise(col(\"prediction\"))) \\\n",
    "            .withColumn(\"prediction\", when(col(\"prediction\") > 5.0, 5.0).otherwise(col(\"prediction\"))) \\\n",
    "            .na.fill(3.52)\n",
    "%time predict_clean.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_clean.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------------------+\n",
      "|userId|movieId|            rating|\n",
      "+------+-------+------------------+\n",
      "|     1|   1414| 3.961900234222412|\n",
      "|     1|   2346| 4.125975608825684|\n",
      "|     1|   5278| 3.106297492980957|\n",
      "|     1|   9303| 4.092289447784424|\n",
      "|     1|  11817|4.3787150382995605|\n",
      "+------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 530 ms\n"
     ]
    }
   ],
   "source": [
    "# make output dataframe\n",
    "output = predict_clean.select('userId', 'movieId', col('prediction').alias('rating')) \\\n",
    "                    .orderBy(['userId', 'movieId'])\n",
    "%time output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write csv file to hdfs and copy to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "# write csv file with predictions\n",
    "%time output.coalesce(1).write.csv('/user/sergey.zaytsev/lab09', header=True, sep=',', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 sergey.zaytsev sergey.zaytsev          0 2019-06-11 16:42 /user/sergey.zaytsev/lab09/_SUCCESS\r\n",
      "-rw-r--r--   3 sergey.zaytsev sergey.zaytsev  321316751 2019-06-11 16:42 /user/sergey.zaytsev/lab09/part-00000-1f06842c-c7a0-4d67-b4d3-968b3034057b-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/sergey.zaytsev/lab09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy output file to local directory\n",
    "!hadoop fs -copyToLocal /user/sergey.zaytsev/lab09/part-00000-1f06842c-c7a0-4d67-b4d3-968b3034057b-c000.csv ~/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shut down spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Data (Ignore for now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tags.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!hadoop fs -head /labs/lab09data/tags.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"userId\", IntegerType()),\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"tag\", StringType())\n",
    "])\n",
    "tags = spark.read.csv('/labs/lab09data/tags.csv', schema=schema, header=True, sep=\",\")\n",
    "tags.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time tags.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!hadoop fs -head /labs/lab09data/movies.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"genres\", StringType())\n",
    "])\n",
    "movies = spark.read.csv('/labs/lab09data/movies.csv', schema=schema, header=True, sep=\",\")\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time movies.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### links.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!hadoop fs -head /labs/lab09data/links.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"imdbId\", IntegerType()),\n",
    "    StructField(\"tmdbId\", IntegerType())\n",
    "])\n",
    "links = spark.read.csv('/labs/lab09data/links.csv', schema=schema, header=True, sep=\",\")\n",
    "links.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time links.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
